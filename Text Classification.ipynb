{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f359416f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('hate_speech.csv') \n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b561aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5242, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfff05e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    3000\n",
       "1    2242\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b13c8d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -  â #ireland consumer price index (mom) climbed from previous 0.2% to 0.5% in may   #blog #silver #gold #forex\n",
      "2 - we are so selfish. #orlando #standwithorlando #pulseshooting #orlandoshooting #biggerproblems #selfish #heabreaking   #values #love #\n",
      "3 - i get to see my daddy today!!   #80days #gettingfed\n",
      "4 - ouch...junior is angryð#got7 #junior #yugyoem   #omg \n",
      "5 - i am thankful for having a paner. #thankful #positive     \n"
     ]
    }
   ],
   "source": [
    "for index, tweet in enumerate(dataset[\"tweet\"][10:15]):\n",
    "\n",
    "    print(index+1,\"-\",tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcadd2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "\n",
    "    text = re.sub(r'[^a-zA-Z\\']', ' ', text)\n",
    "\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "\n",
    "    text = text.lower()  \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0a17526",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['clean_text'] = dataset.tweet.apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc01231b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>user  user thanks for  lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide  society now     motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "      <td>huge fan fare and big talking before the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
       "      <td>user camping tomorrow  user  user  user  use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>the next school year is the year for exams.ð...</td>\n",
       "      <td>the next school year is the year for exams    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
       "      <td>we won    love the land     allin  cavs  champ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
       "      <td>user  user welcome here    i'm   it's so  gr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3      0                                bihday your majesty   \n",
       "3   4      0  #model   i love u take with u all the time in ...   \n",
       "4   5      0             factsguide: society now    #motivation   \n",
       "5   6      0  [2/2] huge fan fare and big talking before the...   \n",
       "6   7      0   @user camping tomorrow @user @user @user @use...   \n",
       "7   8      0  the next school year is the year for exams.ð...   \n",
       "8   9      0  we won!!! love the land!!! #allin #cavs #champ...   \n",
       "9  10      0   @user @user welcome here !  i'm   it's so #gr...   \n",
       "\n",
       "                                          clean_text  \n",
       "0    user when a father is dysfunctional and is s...  \n",
       "1   user  user thanks for  lyft credit i can't us...  \n",
       "2                                bihday your majesty  \n",
       "3   model   i love u take with u all the time in ...  \n",
       "4             factsguide  society now     motivation  \n",
       "5        huge fan fare and big talking before the...  \n",
       "6    user camping tomorrow  user  user  user  use...  \n",
       "7  the next school year is the year for exams    ...  \n",
       "8  we won    love the land     allin  cavs  champ...  \n",
       "9    user  user welcome here    i'm   it's so  gr...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcf7cf73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# listing stop words\n",
    "\n",
    "len(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd145008",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\n",
    "    'a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and', 'any', 'are', \n",
    "    'aren\\'t', 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', \n",
    "    'both', 'but', 'by', 'can\\'t', 'cannot', 'could', 'couldn\\'t', 'did', 'didn\\'t', 'do', \n",
    "    'does', 'doesn\\'t', 'doing', 'don\\'t', 'down', 'during', 'each', 'few', 'for', 'from', \n",
    "    'further', 'had', 'hadn\\'t', 'has', 'hasn\\'t', 'have', 'haven\\'t', 'having', 'he', 'he\\'d', \n",
    "    'he\\'ll', 'he\\'s', 'her', 'here', 'here\\'s', 'hers', 'herself', 'him', 'himself', 'his', \n",
    "    'how', 'how\\'s', 'i', 'i\\'d', 'i\\'ll', 'i\\'m', 'i\\'ve', 'if', 'in', 'into', 'is', 'isn\\'t', \n",
    "    'it', 'it\\'s', 'its', 'itself', 'let\\'s', 'me', 'more', 'most', 'mustn\\'t', 'my', 'myself', \n",
    "    'no', 'nor', 'not', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'ought', 'our', \n",
    "    'ours', 'ourselves', 'out', 'over', 'own', 'same', 'shan\\'t', 'she', 'she\\'d', 'she\\'ll', \n",
    "    'she\\'s', 'should', 'shouldn\\'t', 'so', 'some', 'such', 'than', 'that', 'that\\'s', 'the', \n",
    "    'their', 'theirs', 'them', 'themselves', 'then', 'there', 'there\\'s', 'these', 'they', \n",
    "    'they\\'d', 'they\\'ll', 'they\\'re', 'they\\'ve', 'this', 'those', 'through', 'to', 'too', \n",
    "    'under', 'until', 'up', 'very', 'was', 'wasn\\'t', 'we', 'we\\'d', 'we\\'ll', 'we\\'re', \n",
    "    'we\\'ve', 'were', 'weren\\'t', 'what', 'what\\'s', 'when', 'when\\'s', 'where', 'where\\'s', \n",
    "    'which', 'while', 'who', 'who\\'s', 'whom', 'why', 'why\\'s', 'with', 'won\\'t', 'would', \n",
    "    'wouldn\\'t', 'you', 'you\\'d', 'you\\'ll', 'you\\'re', 'you\\'ve', 'your', 'yours', \n",
    "    'yourself', 'yourselves'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a39d106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate word frequency\n",
    "\n",
    "def gen_freq(text):\n",
    "\n",
    "    #Will store the list of words\n",
    "\n",
    "    word_list = []\n",
    "\n",
    "    #Loop over all the tweets and extract words into word_list\n",
    "\n",
    "    for tw_words in text.split():\n",
    "\n",
    "        word_list.extend(tw_words)\n",
    "\n",
    "    #Create word frequencies using word_list\n",
    "\n",
    "    word_freq = pd.Series(word_list).value_counts()\n",
    "\n",
    "    #Drop the stopwords during the frequency calculation\n",
    "\n",
    "    word_freq = word_freq.drop(stop_words, errors='ignore')\n",
    "\n",
    "    return word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f82749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check whether a negation term is present in the text\n",
    "\n",
    "def any_neg(stop_words):\n",
    "\n",
    "    for word in words:\n",
    "\n",
    "        if word in ['n', 'no', 'non', 'not'] or re.search(r\"\\wn't\", word):\n",
    "\n",
    "            return 1\n",
    "\n",
    "        else:\n",
    "\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5da75544",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check whether one of the 100 rare words is present in the text\n",
    "\n",
    "def any_rare(stop_words, rare_100):\n",
    "\n",
    "    for word in stop_words:\n",
    "\n",
    "        if word in rare_100:\n",
    "\n",
    "            return 1\n",
    "\n",
    "        else:\n",
    "\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "345533cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check whether prompt words are present\n",
    "\n",
    "def is_question(stop_words):\n",
    "\n",
    "    for word in stop_words:\n",
    "\n",
    "        if word in ['when', 'what', 'how', 'why', 'who', 'where']:\n",
    "\n",
    "            return 1\n",
    "\n",
    "        else:\n",
    "\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a1a21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq = gen_freq(dataset.clean_text.str)\n",
    "\n",
    "#100 most rare words in the dataset\n",
    "\n",
    "rare_100 = word_freq[-100:] # last 100 rows/words\n",
    "\n",
    "#Number of words in a tweet\n",
    "\n",
    "dataset['word_count'] = dataset.clean_text.str.split().apply(lambda x: len(x))\n",
    "\n",
    "#Negation present or not\n",
    "\n",
    "dataset['any_neg'] = dataset.clean_text.str.split().apply(lambda x: any_neg(x))\n",
    "\n",
    "#Prompt present or not\n",
    "\n",
    "dataset['is_question'] = dataset.clean_text.str.split().apply(lambda x: is_question(x))\n",
    "\n",
    "#Any of the most 100 rare words present or not\n",
    "\n",
    "dataset['any_rare'] = dataset.clean_text.str.split().apply(lambda x: any_rare(x, rare_100))\n",
    "\n",
    "#Character count of the tweet\n",
    "\n",
    "dataset['char_count'] = dataset.clean_text.apply(lambda x: len(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
